{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with an CNN and a Pretrained Embedding (GloVe)\n",
    "\n",
    "In this notebook, I implement a convolutional neural network (CNN) that will be trained using the traning set of the IMDB reviews database and it will be tested on its corresponding testing set. The databases has been downloaded from:\n",
    "__[http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/)__\n",
    "\n",
    "In our neural network we will make use of GloVe, a pre-trained embedding layer whose details can be consulted here:\n",
    "__[https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)__\n",
    "\n",
    "Words will be turned into numerical vector by the means of that embedding layer. The word vector sequences will be first \"analyzed\" using one (words), three (trigrams), five (pentagrams) and seven-word (heptagrams) wide filters. \n",
    "\n",
    "The model is implemented in python using pyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Let's import the modules we will use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPUs?\n",
    "Let's check if a GPU is available and select the device use for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load the pretrained embedding\n",
    "\n",
    "We will use glove.6B.300d.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the embedding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_int = {'<pad>': 0}\n",
    "emb_vectors = ['Fill at the End']\n",
    "words = ['<pad>']\n",
    "with open(glove_file, 'r',encoding='utf-8' ) as f:\n",
    "    idx = 1\n",
    "    for line in f:\n",
    "        #line = line.decode().split()\n",
    "        line = line.split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word_to_int[word] = idx\n",
    "        emb_vectors.append(np.array(line[1:]).astype(np.float))\n",
    "        idx += 1\n",
    "#print(line)\n",
    "emb_vectors[0] = np.zeros_like(emb_vectors[1])\n",
    "#convert to np array\n",
    "emb_vectors = np.array(emb_vectors)\n",
    "#convert to torch tensor\n",
    "emb_vectors = torch.from_numpy(emb_vectors).type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400002\n",
      "<pad> the <unk>\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(words[0],words[1],words[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([ 0.0466,  0.2132, -0.0074, -0.4585, -0.0356,  0.2364, -0.2884,  0.2152,\n",
      "        -0.1349, -1.6413, -0.2609,  0.0324,  0.0566, -0.0433, -0.0217,  0.2248,\n",
      "        -0.0751, -0.0670, -0.1425,  0.0388, -0.1895,  0.2998,  0.3930,  0.1789,\n",
      "        -0.1734, -0.2118,  0.2362, -0.0637, -0.4232, -0.1166,  0.0938,  0.1730,\n",
      "        -0.3307,  0.4911, -0.6899, -0.0925,  0.2474, -0.1799,  0.0979,  0.0831,\n",
      "         0.1530, -0.2728, -0.0389,  0.5445,  0.5374,  0.2910, -0.0074,  0.0479,\n",
      "        -0.4076, -0.0268,  0.1792,  0.0110, -0.1096, -0.2639,  0.0740,  0.2624,\n",
      "        -0.1508,  0.3462,  0.2576,  0.1197, -0.0371, -0.0716,  0.4390, -0.0408,\n",
      "         0.0164, -0.4464,  0.1720,  0.0462,  0.0586,  0.0415,  0.5395,  0.5250,\n",
      "         0.1136, -0.0483, -0.3638,  0.1870,  0.0928, -0.1113, -0.4209,  0.1399,\n",
      "        -0.3934, -0.0679,  0.1219,  0.1671,  0.0752, -0.0155, -0.1950,  0.1964,\n",
      "         0.0532,  0.2517, -0.3485, -0.1064, -0.3469, -0.1902, -0.2004,  0.1215,\n",
      "        -0.2921,  0.0234, -0.1162, -0.3577,  0.0623,  0.3588,  0.0291,  0.0073,\n",
      "         0.0049, -0.1505, -0.1231,  0.1934,  0.1217,  0.4450,  0.2515,  0.1078,\n",
      "        -0.1772,  0.0387,  0.0815,  0.1467,  0.0637,  0.0613, -0.0756, -0.3772,\n",
      "         0.0159, -0.3034,  0.2837, -0.0420, -0.0407, -0.1527,  0.0750,  0.1558,\n",
      "         0.1043,  0.3139,  0.1931,  0.1943,  0.1519, -0.1019, -0.0188,  0.2079,\n",
      "         0.1337,  0.1904, -0.2556,  0.3040, -0.0190,  0.2015, -0.4211, -0.0075,\n",
      "        -0.2798, -0.1931,  0.0462,  0.1997, -0.3021,  0.2573,  0.6811, -0.1941,\n",
      "         0.2398,  0.2249,  0.6522, -0.1356, -0.1738, -0.0482, -0.1186,  0.0022,\n",
      "        -0.0195,  0.1195,  0.1935, -0.4082, -0.0830,  0.1663, -0.1060,  0.3586,\n",
      "         0.1692,  0.0726, -0.2480, -0.1002, -0.5249, -0.1775, -0.3665,  0.2618,\n",
      "        -0.0121,  0.0832, -0.2153,  0.4105,  0.2914,  0.3087,  0.0789,  0.3221,\n",
      "        -0.0410, -0.1097, -0.0920, -0.1234, -0.1642,  0.3538, -0.0828,  0.3317,\n",
      "        -0.2474, -0.0489,  0.1575,  0.1899, -0.0266,  0.0633, -0.0107,  0.3409,\n",
      "         1.4106,  0.1342,  0.2819, -0.2594,  0.0553, -0.0524, -0.2579,  0.0191,\n",
      "        -0.0221,  0.3211,  0.0688,  0.5121,  0.1648, -0.2019,  0.2923,  0.0986,\n",
      "         0.0131, -0.1065,  0.1351, -0.0453,  0.2070, -0.4843, -0.4471,  0.0033,\n",
      "         0.0029, -0.1098, -0.2333,  0.2244, -0.1050,  0.1234,  0.1098,  0.0490,\n",
      "        -0.2516,  0.4032,  0.3532,  0.1865, -0.0236, -0.1273,  0.1147,  0.2736,\n",
      "        -0.2187,  0.0158,  0.8175, -0.0238, -0.8547, -0.1620,  0.1808,  0.0280,\n",
      "        -0.1434,  0.0013, -0.0917, -0.0897,  0.1111, -0.1670,  0.0684, -0.0874,\n",
      "        -0.0398,  0.0142,  0.2119,  0.2858, -0.2880, -0.0590, -0.0324, -0.0047,\n",
      "        -0.1705, -0.0347, -0.1149,  0.0751,  0.0995,  0.0482, -0.0738, -0.4182,\n",
      "         0.0041,  0.4441, -0.1606,  0.1429, -2.2628, -0.0273,  0.8131,  0.7742,\n",
      "        -0.2564, -0.1158, -0.1198, -0.2136,  0.0284,  0.2726,  0.0310,  0.0968,\n",
      "         0.0068,  0.1408, -0.0131, -0.2969, -0.0799,  0.1950,  0.0315,  0.2851,\n",
      "        -0.0875,  0.0091, -0.2099,  0.0539])\n",
      "tensor([ 0.4292, -0.2969,  0.1501,  0.2452, -0.0035, -0.0577,  0.1409, -0.2223,\n",
      "         0.2212,  0.7672, -0.0773, -0.0711,  0.0629, -0.2202, -0.1082, -0.3014,\n",
      "         0.2322,  0.1687, -0.0045,  0.1683, -0.0579, -0.0363, -0.2735, -0.1630,\n",
      "         0.2394, -0.0119,  0.0447,  0.1053,  0.1029, -0.0233, -0.0114, -0.3817,\n",
      "         0.0612,  0.0171,  0.4155, -0.1091,  0.0960,  0.1915, -0.0075, -0.1946,\n",
      "        -0.0432,  0.2598,  0.0053, -0.1836,  0.2252, -0.0188, -0.1582, -0.5869,\n",
      "         0.2493, -0.1303, -0.0537,  0.0316, -0.1856,  0.0610, -0.0851, -0.0965,\n",
      "         0.2786, -0.2473, -0.1539,  0.0418,  0.0704, -0.0623, -0.2849,  0.0152,\n",
      "         0.1440,  0.3359, -0.2883, -0.0025, -0.0876, -0.0574,  0.0067, -0.0753,\n",
      "        -0.0678, -0.0566,  0.1930,  0.0250, -0.3919, -0.1593,  0.2612,  0.1022,\n",
      "         0.0877,  0.0433, -0.1798, -0.1897,  0.0511, -0.0164, -0.0071, -0.3277,\n",
      "        -0.2075, -0.0213,  0.1167, -0.0676,  0.2681,  0.0962,  0.0516, -0.0365,\n",
      "         0.3172, -0.1589, -0.0555,  0.2879, -0.1407, -0.2257, -0.0546,  0.2120,\n",
      "        -0.0359, -0.0980, -0.0192, -0.1864,  0.2986, -0.1337, -0.1143,  0.3033,\n",
      "         0.1427,  0.0511,  0.1112, -0.1064,  0.2469, -0.0652,  0.1377,  0.2276,\n",
      "        -0.0368,  0.1394, -0.1103, -0.0729,  0.0966,  0.0341,  0.2667, -0.0070,\n",
      "         0.0285, -0.2860,  0.1485, -0.3518, -0.1805,  0.0751, -0.0414,  0.0232,\n",
      "         0.1345,  0.2345,  0.0078, -0.4310, -0.1712, -0.0481, -0.1448, -0.1056,\n",
      "         0.4121, -0.0439, -0.1226, -0.1055,  0.1864, -0.0875, -0.3612,  0.1370,\n",
      "        -0.1449,  0.0686, -0.4516, -0.0748,  0.2358, -0.1471, -0.2086,  0.0403,\n",
      "        -0.2592,  0.2911, -0.0382, -0.2061, -0.0899,  0.0436, -0.1813, -0.0927,\n",
      "         0.0721, -0.3280, -0.0489, -0.0824,  0.5907, -0.3320,  0.1504, -0.0933,\n",
      "         0.1255,  0.2314,  0.0384, -0.3100, -0.1767, -0.1762, -0.0883,  0.0158,\n",
      "         0.2118,  0.2100,  0.3736,  0.0085,  0.1620, -0.2207,  0.1932, -0.1714,\n",
      "         0.0398, -0.0031,  0.0125, -0.0605, -0.0638, -0.1928,  0.0692, -0.2356,\n",
      "        -0.6954,  0.0394,  0.0050,  0.0143, -0.0900, -0.1120,  0.1007, -0.1841,\n",
      "        -0.0590, -0.0465, -0.0151, -0.0513, -0.0988, -0.0367, -0.3037, -0.0170,\n",
      "         0.0807, -0.1951,  0.1504, -0.1495, -0.3181,  0.1109,  0.2607, -0.0893,\n",
      "        -0.0852, -0.1558, -0.0601, -0.0389,  0.3090,  0.1097,  0.0357, -0.1583,\n",
      "        -0.1892,  0.0513,  0.0812, -0.3440, -0.2057, -0.1531,  0.2535, -0.0531,\n",
      "         0.0590,  0.0415, -0.1990, -0.0431,  0.3675,  0.0419, -0.1595,  0.1763,\n",
      "         0.3569, -0.0974, -0.1644, -0.0779,  0.2681,  0.1840, -0.2349,  0.2504,\n",
      "         0.1221,  0.0239, -0.2938, -0.0107, -0.1726,  0.0896, -0.2492, -0.1783,\n",
      "        -0.1001,  0.1745,  0.0815, -0.2593, -0.0361, -0.1837,  0.1232,  0.1818,\n",
      "        -0.1183, -0.2754,  0.0096, -0.0358,  0.7829,  0.0814, -0.3090,  0.0045,\n",
      "         0.1725,  0.0388,  0.0374,  0.0566,  0.0239, -0.2575,  0.1575, -0.2822,\n",
      "        -0.1325,  0.2175,  0.1281,  0.0976, -0.1310, -0.1428, -0.1755, -0.1690,\n",
      "        -0.0225,  0.2898,  0.3262, -0.0591])\n"
     ]
    }
   ],
   "source": [
    "print(emb_vectors[0])\n",
    "print(emb_vectors[1])\n",
    "print(emb_vectors[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load in, tokenize and visualize the data\n",
    "\n",
    "The download data is already divied into train and test data. Each folder is further divided into positive (7-10/10 stars reviews) and negative reviews (1-4/10 stars reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SET\n",
      "Number of positive reviews: 12500 Number of negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "#training positive reviews directory\n",
    "train_pos_dir = r'aclImdb/train/pos/'\n",
    "#negative positive reviews directory\n",
    "train_neg_dir = r'aclImdb/train/neg/'\n",
    "\n",
    "#List of files with training positive review\n",
    "train_pos_rev_files = os.listdir(train_pos_dir)\n",
    "#List of files with training negative review\n",
    "train_neg_rev_files = os.listdir(train_neg_dir)\n",
    "print('TRAIN SET')\n",
    "print('Number of positive reviews:',len(train_pos_rev_files),'Number of negative reviews:',len(train_neg_rev_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep track of the number of stars (1-10) awarded to each positive and negative review in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_stars = []\n",
    "for file in train_pos_rev_files:\n",
    "    full_train_stars.append(int(file.split('_')[1].split('.')[0]))\n",
    "for file in train_neg_rev_files:\n",
    "    full_train_stars.append(int(file.split('_')[1].split('.')[0]))    \n",
    "full_train_stars = np.array(full_train_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET\n",
      "Number of positive reviews: 12500 Number of negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "#training positive reviews directory\n",
    "test_pos_dir = r'aclImdb/test/pos/'\n",
    "#negative positive reviews directory\n",
    "test_neg_dir = r'aclImdb/test/neg/'\n",
    "\n",
    "#List of files with training positive review\n",
    "test_pos_rev_files = os.listdir(test_pos_dir)\n",
    "#List of files with training negative review\n",
    "test_neg_rev_files = os.listdir(test_neg_dir)\n",
    "print('TEST SET')\n",
    "print('Number of positive reviews:',len(test_pos_rev_files),'Number of negative reviews:',len(test_neg_rev_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep track of the number of stars (1-10) awarded to each positive and negative review in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stars = []\n",
    "for file in test_pos_rev_files:\n",
    "    test_stars.append(int(file.split('_')[1].split('.')[0]))\n",
    "for file in test_neg_rev_files:\n",
    "    test_stars.append(int(file.split('_')[1].split('.')[0]))    \n",
    "test_stars = np.array(test_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 5- and 6-star reviews are not included in the train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  7  8  9 10]\n",
      "[ 1  2  3  4  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(full_train_stars))\n",
    "print(np.unique(test_stars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Matrices\n",
    "Let's create numpy arrays that hold the train and test labels. 1 stands for positive and 0 for negative. Since we will stack first the positive reviews and the the negative ones, the first 12500 elements are ones and the next 12500 are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train target array\n",
    "full_train_target = np.zeros(len(train_neg_rev_files)+len(train_neg_rev_files), dtype=int)\n",
    "full_train_target[:len(train_neg_rev_files)] = 1\n",
    "#Test target array\n",
    "test_target = np.zeros(len(test_neg_rev_files)+len(test_neg_rev_files), dtype=int)\n",
    "test_target[:len(test_neg_rev_files)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "print(full_train_target.shape, test_target.shape)\n",
    "print(full_train_target.mean(), test_target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Contractions\n",
    "The following function expands common english contractions. There is obviously  plenty of room for improvement. Some \n",
    "actions are 100% justified (can't and cannot into can not), while others are rather arbitrary ('s into is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_contractions(text):\n",
    "    # Turn ain't into am not (it could be many other oprions such us is not,...)\n",
    "    text = text.replace(\"ain't\", \"am not\")\n",
    "    #Turn can't and annot into can not\n",
    "    text = text.replace(\"can't\", \"can not\").replace(\"cannot\", \"can not\")\n",
    "    #Turn shan't into shall not\n",
    "    text = text.replace(\"shan't\", \"shall not\")\n",
    "    #Turn won't into will not\n",
    "    text = text.replace(\"won't\", \"will not\")\n",
    "    #Turn y'all into you all\n",
    "    text = text.replace(\"y'all\", \"you all\")\n",
    "    #Turn n't into not\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    #Turn 'd into would (it might be had too)\n",
    "    text = text.replace(\"'d\", \" would\")\n",
    "    #Turn 'll into will\n",
    "    text = text.replace(\"'ll\", \" will\")\n",
    "    #Turn 're into are\n",
    "    text = text.replace(\"'re\", \" are\")\n",
    "    #Turn 'm into am\n",
    "    text = text.replace(\"'m\", \" am\")\n",
    "    #Turn 's into is (it could also be has or the posssesive)\n",
    "    text = text.replace(\"'s\", \" is\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews as List of Words\n",
    "For each review we convert every character to lower case, remove english contructions, then remove punctuation and finally split it into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_reviews=[]\n",
    "#Read and tokenize positive reviews\n",
    "for file_name in train_pos_rev_files:\n",
    "    with open(train_pos_dir+file_name, 'r',encoding=\"utf8\") as f:\n",
    "        review = f.read().lower()\n",
    "        #remove some contractions\n",
    "        review = remove_contractions(review)\n",
    "        #remove punctuation\n",
    "        review = ''.join([c for c in review if c not in punctuation])\n",
    "        #split in words\n",
    "        review = review.split()  \n",
    "    full_train_reviews.append(review)\n",
    "\n",
    "#Read and tokenize negative reviews\n",
    "for file_name in train_neg_rev_files:\n",
    "    with open(train_neg_dir+file_name, 'r',encoding=\"utf8\") as f:\n",
    "        review = f.read().lower()\n",
    "        #remove some contractions\n",
    "        review = remove_contractions(review)\n",
    "        #remove punctuation\n",
    "        review = ''.join([c for c in review if c not in punctuation])\n",
    "        #split in words\n",
    "        review = review.split()  \n",
    "    full_train_reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "['br', 'br', 'if', 'you', 'like', 'rap', 'or', 'hiphop', 'watch', 'this', 'movie', 'although', 'it', 'is', 'funny', 'if', 'you', 'do', 'not', 'get', 'the', 'references', 'as', 'a', 'straight', 'comedybr', 'br', 'have', 'not', 'seen', 'much', 'of', 'the', 'much', 'hyped', 'cb4', 'but', 'what', 'i', 'did', 'see', 'did', 'not', 'have', 'the', 'heart', 'that', 'this', 'little', 'stormer', 'hasbr', 'br', 'have', 'not', 'heard', 'from', 'the', 'people', 'involved', 'since', 'which', 'is', 'a', 'surprise', 'the', 'film', 'is', 'very', 'similar', 'to', 'spinal', 'tap', 'which', 'is', 'no', 'bad', 'thing', 'and', 'i', 'think', 'a', 'lot', 'of', 'the', 'dialogue', 'while', 'priceless', 'in', 'tap', 'is', 'funnier', 'here', 'probably', 'because', 'i', 'am', 'more', 'into', 'rap', 'than', 'rock', 'theses', 'days', 'so', 'my', 'own', 'judgment', 'does', 'cloud', 'that', 'pointbr', 'br', 'the', 'rap', 'songs', 'are', 'funny', 'as', 'hell', 'and', 'it', 'is', 'basically', 'spot', 'the', 'reference', 'for', 'most', 'of', 'the', 'film', 'not', 'all', 'of', 'them', 'are', 'inyourface', 'which', 'means', 'the', 'physical', 'comedy', 'and', 'the', 'oneliners', 'get', 'priority', 'over', 'the', 'takeoffsbr', 'br', 'great', 'fun', 'one', 'to', 'watch', 'twice', 'if', 'there', 'ever', 'was', 'a', 'movie']\n"
     ]
    }
   ],
   "source": [
    "print(len(full_train_reviews))\n",
    "print(full_train_reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews=[]\n",
    "#Read and tokenize positive reviews\n",
    "for file_name in test_pos_rev_files:\n",
    "    with open(test_pos_dir+file_name, 'r',encoding=\"utf8\") as f:\n",
    "        review = f.read().lower()\n",
    "        #remove some contractions\n",
    "        review = remove_contractions(review)\n",
    "        #remove punctuation\n",
    "        review = ''.join([c for c in review if c not in punctuation])\n",
    "        #split in words\n",
    "        review = review.split()  \n",
    "    test_reviews.append(review)\n",
    "\n",
    "#Read and tokenize negative reviews\n",
    "for file_name in test_neg_rev_files:\n",
    "    with open(test_neg_dir+file_name, 'r',encoding=\"utf8\") as f:\n",
    "        review = f.read().lower()\n",
    "        #remove some contractions\n",
    "        review = remove_contractions(review)\n",
    "        #remove punctuation\n",
    "        review = ''.join([c for c in review if c not in punctuation])\n",
    "        #split in words\n",
    "        review = review.split()  \n",
    "    test_reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "['the', 'dresser', 'is', 'perhaps', 'the', 'most', 'refined', 'of', 'backstage', 'films', 'the', 'film', 'is', 'brimming', 'with', 'wit', 'and', 'spirit', 'for', 'the', 'most', 'part', 'provided', 'by', 'the', 'energetic', 'character', 'of', 'norman', 'tom', 'courtenay', 'although', 'his', 'character', 'is', 'clearly', 'gay', 'and', 'certainly', 'has', 'an', 'attraction', 'for', 'the', 'lead', 'performer', 'albert', 'finney', 'that', 'he', 'assists', 'the', 'film', 'never', 'dwells', 'on', 'it', 'or', 'makes', 'it', 'more', 'than', 'it', 'isbr', 'br', 'the', 'gritty', 'style', 'of', 'peter', 'yates', 'that', 'worked', 'so', 'well', 'in', 'bullitt', 'is', 'again', 'on', 'display', 'and', 'gives', 'the', 'film', 'a', 'sense', 'of', 'realism', 'and', 'coherence', 'this', 'is', 'much', 'appreciated', 'in', 'a', 'story', 'that', 'could', 'so', 'easily', 'have', 'become', 'tedious', 'in', 'the', 'end', 'the', 'dresser', 'will', 'bore', 'many', 'people', 'silly', 'but', 'it', 'will', 'truly', 'be', 'a', 'delight', 'to', 'those', 'who', 'love', 'british', 'cinemabr', 'br', '77', 'out', 'of', '10']\n"
     ]
    }
   ],
   "source": [
    "print(len(test_reviews))\n",
    "print(test_reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Sets\n",
    "\n",
    "We will divide our full train set into a train set and a validation set that will help us to control how our model generalize.\n",
    "The validation set will be just 10% of the original train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#90% will remain as training data\n",
    "train_size = 0.9; test_size = 1-train_size\n",
    "(train_reviews, valid_reviews, train_y, valid_y, \n",
    " train_stars, valid_stars) = train_test_split(full_train_reviews, full_train_target, full_train_stars,\n",
    "                                              random_state=123, shuffle=True,\n",
    "                                              train_size=train_size, test_size=test_size,stratify=full_train_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500 (22500,) (22500,)\n",
      "2500 (2500,) (2500,)\n",
      "0.5 0.5\n"
     ]
    }
   ],
   "source": [
    "#Print out the shapes of your resultant feature data\n",
    "print(len(train_reviews), train_y.shape, train_stars.shape)\n",
    "print(len(valid_reviews), valid_y.shape, valid_stars.shape)\n",
    "print(train_y.mean(), valid_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To keep it simple let's create a test_y variable\n",
    "test_y = test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the size of the reviews\n",
    "It is important to xhoose now the word size of our review before we build our vocabulary. That will prevent us from including\n",
    "words that may appear frequently in our reviews if we keep all the words but not more than five times if we keep, \n",
    "let's say, the first 50 words only. Of course, the larger the sequence considered the less important this would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Sequence length #########\n",
    "seq_length = 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Let's get our data into the proper form to feed into the network. Since we're using embedding layers, we'll need to encode each word with an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the words\n",
    "\n",
    "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our reviews into integers so they can be passed into the network.Also we are going to keep the value zero to represent the padding and the value 1 to represent every word\n",
    "that appears least than five times in our train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tokenize the reviews into integers\n",
    "#Index of unknown token\n",
    "unk = word_to_int['<unk>']\n",
    "# train set\n",
    "train_reviews_int = []\n",
    "num_words = 0\n",
    "num_unks = 0\n",
    "for review in train_reviews:\n",
    "    review_int = []\n",
    "    for word in review:\n",
    "        if word in word_to_int:\n",
    "            num_words += 1\n",
    "            review_int.append(word_to_int[word])\n",
    "        else:\n",
    "            num_unks += 1\n",
    "            review_int.append(unk)\n",
    "    train_reviews_int.append(review_int)       \n",
    "    \n",
    "# validation set\n",
    "valid_reviews_int = []\n",
    "for review in valid_reviews:\n",
    "    valid_reviews_int.append([word_to_int.get(word,unk) for word in review])\n",
    "# test set\n",
    "test_reviews_int = []\n",
    "for review in test_reviews:\n",
    "    test_reviews_int.append([word_to_int.get(word,unk) for word in review])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Known words: 5238395 \t Unknown words: 106423\n"
     ]
    }
   ],
   "source": [
    "print('Train Set')\n",
    "print(f'Known words: {num_words} \\t Unknown words: {num_unks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test your code**\n",
    "\n",
    "As a text that you've implemented the dictionary correctly, print out the number of unique words in your vocabulary and the contents of the first, tokenized review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized review: \n",
      " [38, 15, 1, 1608, 1006, 42, 662, 1137, 5, 254, 6, 18, 1, 4940, 4, 40, 4038, 6541, 15, 2956, 1, 1608, 1006, 42, 34, 662, 542, 567, 62, 38, 1006, 264, 67, 42, 16, 8, 366, 3268, 4, 35205, 6, 75562, 6, 2318, 16, 15155, 103, 42, 805, 55, 31, 1, 28186, 1006, 13, 95, 31, 1015, 109, 21, 120, 37, 34, 1, 3253, 1, 817, 38954, 971, 391, 436, 18, 30411, 30411, 1, 2602, 391, 34, 805, 54, 44, 3376, 7, 78, 225600, 78, 68805, 8736, 78, 5116, 1740, 6, 7943, 54, 34, 8, 7770, 438, 12402, 36456, 2842, 1, 187, 274, 37817, 33, 937, 57, 74, 5116, 26026, 191, 14124, 14, 887, 15, 160, 8, 436, 18, 8980, 225600, 1, 3163, 10109, 191, 139, 2375, 1, 593, 1750, 6, 72, 8255, 16, 121, 5406, 979, 153, 165, 6203, 1, 21113, 2020, 11364, 16, 7089, 6203, 11, 400001, 492, 1, 1048, 5838, 34974, 16, 18015, 6203, 623, 41839, 362974, 1, 349, 7310, 3527, 205, 5652, 5816, 45623, 64, 15, 85, 2334, 18, 8, 349, 10984, 16, 144, 82, 170, 193, 400001, 30411, 1, 92, 5467, 34974, 792, 17883, 4213, 43, 4577, 11, 8, 1116, 1215, 38, 890, 82, 170, 1117, 1687, 4, 2046, 7, 38, 1006, 3203, 63107, 79290, 1466, 1, 1940, 60, 1, 1453, 124, 135, 23640, 7, 1, 3202, 15, 6, 82, 44, 118, 38, 1006, 84, 82, 33, 153, 144, 97, 4, 1, 124, 16, 37, 23640, 7, 1, 1617, 15, 84, 1, 26475, 2602, 36, 23640, 21, 391, 34, 52, 14, 59356, 35085, 2351, 64, 36, 410, 69, 70, 7, 1, 2249, 3607, 3262, 62, 42, 823, 38, 1006, 4, 747, 1389, 120, 37, 170, 67, 554, 60, 198, 979, 1, 1006, 16]\n",
      "22500\n"
     ]
    }
   ],
   "source": [
    "# print tokens in first review\n",
    "print('Tokenized review: \\n', train_reviews_int[0])\n",
    "print(len(train_reviews_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of the Reviews \n",
    "\n",
    "We have already set for a value of 500 words but it is convinient to check some statistic about the review lenght (mean,\n",
    "median, std). We may even decide to run the whole notebook with a different sequence lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum review length: 10\n",
      "Maximum review length: 2501\n",
      "Mean and Median review length: 237.54746666666668\t177.0\n",
      "Std review length: 175.75619227979803\n"
     ]
    }
   ],
   "source": [
    "review_lens = np.array([len(x) for x in train_reviews_int])\n",
    "\n",
    "print(f\"Minimum review length: {review_lens.min()}\")\n",
    "print(f\"Maximum review length: {review_lens.max()}\")\n",
    "print(f'Mean and Median review length: {review_lens.mean()}\\t{np.median(review_lens)}')\n",
    "print(f'Std review length: {review_lens.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Padding sequences\n",
    "\n",
    "To deal with both short and very long reviews, we'll pad or truncate all our reviews to a specific length. For reviews shorter than some `seq_length`, we'll pad with 0s. For reviews longer than `seq_length`, we can truncate them to the first `seq_length` words. We will work with a sewuence lenght of 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length, alignment='right'):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    features=np.zeros((len(reviews_ints),seq_length),dtype=int)\n",
    "    \n",
    "    if alignment.lower() == 'right':\n",
    "        my_idxs = lambda length: ((seq_length-length),seq_length) \n",
    "    elif alignment.lower() == 'left':\n",
    "        my_idxs = lambda length: (0,seq_length-(seq_length-length)) \n",
    "    elif alignment.lower() == 'center':\n",
    "        my_idxs = lambda length: ((seq_length-length)//2,seq_length-((seq_length-length)-(seq_length-length)//2))\n",
    "    else:\n",
    "        print(alignment, 'is not a valid option for alignment')\n",
    "        pritn('options: right, left, center')\n",
    "        return None\n",
    "    \n",
    "    for i,review in enumerate(reviews_ints):\n",
    "        text = review[:seq_length]\n",
    "        (a,b) = my_idxs(len(text))\n",
    "        features[i,a:b] = text\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "      38     15      1   1608   1006     42    662   1137      5    254\n",
      "       6     18      1   4940      4     40   4038   6541     15   2956\n",
      "       1   1608   1006     42     34    662    542    567     62     38\n",
      "    1006    264     67     42     16      8    366   3268      4  35205\n",
      "       6  75562      6   2318     16  15155    103     42    805     55\n",
      "      31      1  28186   1006     13     95     31   1015    109     21\n",
      "     120     37     34      1   3253      1    817  38954    971    391\n",
      "     436     18  30411  30411      1   2602    391     34    805     54\n",
      "      44   3376      7     78 225600     78  68805   8736     78   5116\n",
      "    1740      6   7943     54     34      8   7770    438  12402  36456\n",
      "    2842      1    187    274  37817     33    937     57     74   5116\n",
      "   26026    191  14124     14    887     15    160      8    436     18\n",
      "    8980 225600      1   3163  10109    191    139   2375      1    593\n",
      "    1750      6     72   8255     16    121   5406    979    153    165\n",
      "    6203      1  21113   2020  11364]]\n",
      "[[    16   7089   6203     11 400001    492      1   1048   5838  34974\n",
      "      16  18015   6203    623  41839 362974      1    349   7310   3527\n",
      "     205   5652   5816  45623     64     15     85   2334     18      8\n",
      "     349  10984     16    144     82    170    193 400001  30411      1\n",
      "      92   5467  34974    792  17883   4213     43   4577     11      8\n",
      "    1116   1215     38    890     82    170   1117   1687      4   2046\n",
      "       7     38   1006   3203  63107  79290   1466      1   1940     60\n",
      "       1   1453    124    135  23640      7      1   3202     15      6\n",
      "      82     44    118     38   1006     84     82     33    153    144\n",
      "      97      4      1    124     16     37  23640      7      1   1617\n",
      "      15     84      1  26475   2602     36  23640     21    391     34\n",
      "      52     14  59356  35085   2351     64     36    410     69     70\n",
      "       7      1   2249   3607   3262     62     42    823     38   1006\n",
      "       4    747   1389    120     37    170     67    554     60    198\n",
      "     979      1   1006     16      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "train_x = pad_features(train_reviews_int, seq_length=seq_length, alignment='center')\n",
    "valid_x = pad_features(valid_reviews_int, seq_length=seq_length, alignment='center')\n",
    "test_x = pad_features(test_reviews_int, seq_length=seq_length, alignment='center')\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(train_x)==len(train_reviews_int), \"Your features should have as many rows as reviews.\"\n",
    "assert len(train_x[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# Print the first review \n",
    "print(train_x[:1,:seq_length//2])\n",
    "print(train_x[:1,seq_length//2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DataLoaders and Batching\n",
    "\n",
    "After creating training, test, and validation data, we can create DataLoaders for batching our data into the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x).long(), torch.from_numpy(train_y).long())\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x).long(), torch.from_numpy(valid_y).long())\n",
    "test_data = TensorDataset(torch.from_numpy(test_x).long(), torch.from_numpy(test_y).long())\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader_50 = DataLoader(train_data, shuffle=True, batch_size=50)\n",
    "train_loader_100 = DataLoader(train_data, shuffle=True, batch_size=100)\n",
    "train_loader_150 = DataLoader(train_data, shuffle=True, batch_size=150)\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=100) #No need to shuffle\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=100) #No need to shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 350])\n",
      "Sample input: \n",
      " tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "        27580, 40141,    15, 59013,     7,    38,  3032,    68,  1830,    72,\n",
      "           65,   360,    80,    68,    15,    14,   913,   402,    54,    33,\n",
      "         9675,    23,    72,  8736,     6, 20718,    47, 99819,   163,  2252,\n",
      "           23,     1, 10225,     4,    49,     4,    72,  5978, 19076, 27580,\n",
      "        40141,  2479,    72,  2053,    84,    82,    87,    37,   254,    21,\n",
      "          683,    43,    15,     1,   255,   180,     5,   254, 27580,   128,\n",
      "           38,    15,     1,   183,   255,   874,    30,  4002,   874,     5,\n",
      "          663,    23,    15,   198,  7447,    72,  1714,    32,  1166,     6,\n",
      "        24224,    75,     1,    83,    35,   333,   403,    48,   269,    72,\n",
      "           57, 41045,  3953,  1063,     4,  1088,    18,   286,   333,  7234,\n",
      "         1097,     7,  2944,    26,     1,   487,    47,  8662, 13475,   188,\n",
      "           21,    15,   121,    57,  5745,     6,    20, 21788,    20,   662,\n",
      "           42,    44,  9014,    38,  3032,    11,     8,   192,   174,    80,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_loader_50)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x[0])\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sentiment Network with PyTorch\n",
    "\n",
    "As mentioned we will use a Convolutional Neural Network to analyze the sentiment of reviews. \n",
    "It is important to notice that before any convolutional network the words will be converted into 300-dimensions vectors throughout an pretrained GloVe ambedding layer, and also that the first filter of the convolution will get ride of those 300 dimensions returning 1-dimension points. The first filters will process the original features of the reviews as words, 3-grams and 5-grams. After the first maxpooling layer, the three lines will be concatenated and process together.\n",
    "It is worth mentioning that at the end of the convolutional part of the network a fixed number of values per filter (top_k) will be kept, which will garantee that indenpendently of the length of the sequence, always the same number of features are provided to the fully connected network as inputs. If avg=True, only the mean of those top_k values is provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_glove(vectors):\n",
    "    vocab_size, embedding_dim = vectors.shape\n",
    "    emb_layer = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "    emb_layer.load_state_dict({'weight': vectors})\n",
    "    #Freeze parameters\n",
    "    emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, vocab_size, embedding_dim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The CNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, dp_2d=0.25, dp_fc=0.25, seq_length=None, top_k=3, avg=True):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentCNN, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_size = output_size\n",
    "        self.seq_length = seq_length\n",
    "        self.dp_2d = dp_2d\n",
    "        self.dp_fc = dp_fc        \n",
    "        self.top_k = top_k \n",
    "        self.avg = avg\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=0 )\n",
    "        \n",
    "        # Convolutional network\n",
    "        self.conv_1a = nn.Conv2d(1,8,kernel_size=(1,self.embedding_dim),stride=(1,1),padding=(0,0)) #1-grams\n",
    "        self.conv_1b = nn.Conv2d(1,16,kernel_size=(3,self.embedding_dim),stride=(1,1),padding=(1,0)) #3-grams\n",
    "        self.conv_1c = nn.Conv2d(1,32,kernel_size=(5,self.embedding_dim),stride=(1,1),padding=(2,0)) #5-grams\n",
    "                \n",
    "        self.conv_2a = nn.Conv2d(8,8,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        self.conv_2b = nn.Conv2d(16,16,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        self.conv_2c = nn.Conv2d(32,32,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        \n",
    "        self.maxpool_3 = nn.MaxPool2d(kernel_size=(3,1),stride=(3,1),padding=0)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(56,112,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        self.conv_4 = nn.Conv2d(112,112,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "         \n",
    "        self.conv_5 = nn.Conv2d(112,224,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        self.conv_6 = nn.Conv2d(224,224,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        self.conv_7 = nn.Conv2d(224,224,kernel_size=(3,1),stride=1,padding=(1,0))\n",
    "        \n",
    "        #size = (((((self.seq_length-6-2)//3)-2-2)//3)-2-2)\n",
    "        #self.avgpool = nn.AvgPool2d(kernel_size=(size,1),stride=(size,1),padding=0)\n",
    "        \n",
    "        #Fully connected\n",
    "        if self.avg:\n",
    "            self.fc1 = nn.Linear(224,512)\n",
    "        else:    \n",
    "            self.fc1 = nn.Linear(224 * self.top_k,512)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128, self.output_size)\n",
    "        \n",
    "        # dropout layers\n",
    "        self.dropout2d = nn.Dropout2d(dp_2d)\n",
    "        self.dropout = nn.Dropout(dp_fc)\n",
    "        \n",
    "        # relu and sigmoid layers\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        ####### Embedding #######\n",
    "        x = self.embedding(x)\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        \n",
    "        ####### CNN ###########\n",
    "        #First layer\n",
    "        line_a = self.relu(self.conv_1a(x))\n",
    "        line_b = self.relu(self.conv_1b(x))\n",
    "        line_c = self.relu(self.conv_1c(x))\n",
    "             \n",
    "        line_a = self.dropout2d(self.relu(self.conv_2a(line_a)))\n",
    "        line_b = self.dropout2d(self.relu(self.conv_2b(line_b)))\n",
    "        line_c = self.dropout2d(self.relu(self.conv_2c(line_c)))\n",
    "        \n",
    "        #MaxPooling\n",
    "        line_a = self.maxpool_3(line_a)\n",
    "        line_b = self.maxpool_3(line_b)\n",
    "        line_c = self.maxpool_3(line_c)\n",
    "        \n",
    "        #Merge Featre Maps\n",
    "        x = torch.cat((line_a,line_b,line_c),dim=1)\n",
    "        \n",
    "        #Second layer\n",
    "        x = self.relu(self.conv_3(x))\n",
    "        x = self.dropout2d(self.relu(self.conv_4(x)))\n",
    "        \n",
    "        #MaxPooling\n",
    "        x = self.maxpool_3(x)\n",
    "        \n",
    "        #Third layer\n",
    "        x = self.relu(self.conv_5(x))\n",
    "        x = self.relu(self.conv_6(x))\n",
    "        x = self.dropout2d(self.relu(self.conv_7(x)))\n",
    "        \n",
    "        #MaxPooling\n",
    "        x = self.maxpool_3(x)\n",
    "                             \n",
    "        #Extract top_k per channel\n",
    "        x, _ = torch.topk(x,self.top_k,dim=2)\n",
    "        \n",
    "        if self.avg:\n",
    "            x = F.avg_pool2d(x, kernel_size=x.size()[2:])\n",
    "            \n",
    "        #Flatten the array\n",
    "        if self.avg:\n",
    "            x = x.view(-1, 224)\n",
    "        else:\n",
    "            x= x.view(-1, 224 * self.top_k)\n",
    "        \n",
    "        #### Fully Connected ####\n",
    "        x = self.relu(self.dropout(self.fc1(x)))\n",
    "        x = self.relu(self.dropout(self.fc2(x)))\n",
    "        x = self.sig(self.fc3(x))\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return x\n",
    "    \n",
    "    def freeze_emb(self):\n",
    "        print(\"Embedding won't be trained\")\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_emb(self):\n",
    "        print(\"Embedding will be trained\")\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = {'vocab_size': self.vocab_size, 'output_size': self.output_size, \n",
    "                  'embedding_dim': self.embedding_dim, 'seq_length': self.seq_length, \n",
    "                  'dp_2d': self.dp_2d, 'dp_fc': self.dp_fc, 'top_k': self.top_k, 'avg': self.avg}\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the network\n",
    "\n",
    "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
    "\n",
    "* `emb_vectors`: The tensor containing the raw embedding data.\n",
    "* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n",
    "* `dp_2d`: drop out regularization for the convolutional part\n",
    "* `dp_fc`: drop out regularization for the fully connected part\n",
    "* `top_k`: at the end of the convolutional part, it will keep the highest top_k values per filter\n",
    "* `avg`: whether or not to average those top_k values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentCNN(\n",
       "  (embedding): Embedding(400002, 300, padding_idx=0)\n",
       "  (conv_1a): Conv2d(1, 8, kernel_size=(1, 300), stride=(1, 1))\n",
       "  (conv_1b): Conv2d(1, 16, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_1c): Conv2d(1, 32, kernel_size=(5, 300), stride=(1, 1), padding=(2, 0))\n",
       "  (conv_2a): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_2b): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_2c): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (maxpool_3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(56, 112, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_4): Conv2d(112, 112, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_5): Conv2d(112, 224, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_6): Conv2d(224, 224, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_7): Conv2d(224, 224, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (fc1): Linear(in_features=224, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout2d): Dropout2d(p=0)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (relu): ReLU()\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Created the embedding layer\n",
    "glove_layer, vocab_size, embedding_dim = build_glove(emb_vectors)\n",
    "# Instantiate the model w/ hyperparams\n",
    "net_params = {'vocab_size': vocab_size, 'output_size': 1, 'embedding_dim': embedding_dim, 'seq_length': seq_length,\n",
    "              'dp_2d': 0, 'dp_fc': 0.3, 'top_k': 3, 'avg': True}\n",
    "net = SentimentCNN(**net_params)\n",
    "#Include the GloVe embedding\n",
    "net.embedding = glove_layer\n",
    "\n",
    "#Save the encoding dictionary and the list of words\n",
    "net.words = words\n",
    "net.word_to_int = word_to_int\n",
    "#Move to gpu or cpu device\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "Let's train our net. We will use the Adam optimizer and we evaluate the model every few steps and after each epoch. We will save the best model based on the evaluation loss\n",
    "\n",
    "Training hyparameters:\n",
    "\n",
    "* `lr`: Learning rate for our optimizer.\n",
    "* `L2`: L2 regularization used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr = 0.001\n",
    "L2 = 0\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves the model, optimizer and other parameters into a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(path=None, model=None, optimizer=None, epoch=None, train_loss=None, valid_loss=None, params=None,\n",
    "                   word_to_int=None, words=None):\n",
    "    if path:\n",
    "        my_path=path\n",
    "        print('Using', my_path, 'to save')\n",
    "    else:\n",
    "        my_path='my_model.pt'\n",
    "        print('Using', my_path, 'to save')\n",
    "        \n",
    "    checkpoint = {}\n",
    "    \n",
    "    if model:\n",
    "        checkpoint['model_state_dict']= model.state_dict()\n",
    "    else:\n",
    "        print('No model dictionary saved')\n",
    "    \n",
    "    if params:\n",
    "        checkpoint['params'] = params\n",
    "    else:\n",
    "        print('No model parameters saved')\n",
    "        \n",
    "    if optimizer:\n",
    "        checkpoint['optimizer_state_dict']= optimizer.state_dict()\n",
    "    else:\n",
    "        print('NNo optimizer dictionary saved')\n",
    "        \n",
    "    if epoch:\n",
    "        checkpoint['epoch'] = epoch\n",
    "    else:\n",
    "        print('No current epoch value saved')\n",
    "        \n",
    "    if train_loss:\n",
    "        checkpoint['train_loss'] = train_loss\n",
    "    else:\n",
    "        print('No value of the training loss saved')\n",
    "        \n",
    "    if valid_loss:\n",
    "        checkpoint['valid_loss'] = valid_loss\n",
    "    else:\n",
    "        print('No value of the validation loss saved')\n",
    "        \n",
    "    if word_to_int:\n",
    "        checkpoint['word_to_int'] = word_to_int\n",
    "    else:\n",
    "        print('No dictionary for encoding words saved')\n",
    "        \n",
    "    if words:\n",
    "        checkpoint['words'] = words\n",
    "    else:\n",
    "        print('No list of words saved')\n",
    "    \n",
    "    torch.save(checkpoint, my_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loads the model, optimizer and other parameters into a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path=None, model=None, optimizer=None):\n",
    "    '''\n",
    "    It overrrides the model and optimizer provided with the saved parameters \n",
    "    and returns the saved epoch, train loss and validation loss'''\n",
    "    if path:\n",
    "        checkpoint = torch.load(path, map_location='cpu') \n",
    "    else:\n",
    "        print('Nothing loaded. Plese provide a file')\n",
    "        return None\n",
    "        \n",
    "    #Load the model state dictionary\n",
    "    my_dict = checkpoint.get('model_state_dict', None)\n",
    "    if my_dict:\n",
    "        model.load_state_dict(my_dict)\n",
    "        model.word_to_int = checkpoint.get('word_to_int', None)\n",
    "        model.words = checkpoint.get('words', None)\n",
    "    else:\n",
    "        print('No model dictionary found')\n",
    "    \n",
    "    #Load the optimizer state dictionary\n",
    "    my_dict = checkpoint.get('optimizer_state_dict', None)\n",
    "    if my_dict:\n",
    "        optimizer.load_state_dict(my_dict)\n",
    "    else:\n",
    "        print('No optimizer dictionary found')    \n",
    "    \n",
    "    #Load the epoch value, train loss and validation loss\n",
    "    epoch = checkpoint.get('epoch', None)\n",
    "    train_loss = checkpoint.get('train_loss', None)\n",
    "    valid_loss = checkpoint.get('valid_loss', None)\n",
    "    \n",
    "    return epoch, train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE THE MODEL HERE ###\n",
    "my_path = 'my_GloVe_CNN_0115.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing the number of intermediate evals at epoch 1\n",
      "225\n",
      "[112]\n",
      "Step: 112\n",
      "Epoch: 1/20... Train Loss: 0.692498... Val Loss: 0.693441\n",
      "Validation loss decreased (inf --> 0.693441).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 225\n",
      "Epoch: 1/20... Train Loss: 0.692814... Val Loss: 0.693163\n",
      "Validation loss decreased (0.693441 --> 0.693163).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Changing the number of intermediate evals at epoch 2\n",
      "225\n",
      "[22, 45, 67, 90, 112, 135, 157, 180, 202]\n",
      "Step: 22\n",
      "Epoch: 2/20... Train Loss: 0.693330... Val Loss: 0.693150\n",
      "Validation loss decreased (0.693163 --> 0.693150).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 45\n",
      "Epoch: 2/20... Train Loss: 0.693157... Val Loss: 0.693121\n",
      "Validation loss decreased (0.693150 --> 0.693121).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 67\n",
      "Epoch: 2/20... Train Loss: 0.693097... Val Loss: 0.693087\n",
      "Validation loss decreased (0.693121 --> 0.693087).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 90\n",
      "Epoch: 2/20... Train Loss: 0.693074... Val Loss: 0.693108\n",
      "Step: 112\n",
      "Epoch: 2/20... Train Loss: 0.693079... Val Loss: 0.692756\n",
      "Validation loss decreased (0.693087 --> 0.692756).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 135\n",
      "Epoch: 2/20... Train Loss: 0.692927... Val Loss: 0.693213\n",
      "Step: 157\n",
      "Epoch: 2/20... Train Loss: 0.692960... Val Loss: 0.693204\n",
      "Step: 180\n",
      "Epoch: 2/20... Train Loss: 0.692718... Val Loss: 0.683941\n",
      "Validation loss decreased (0.692756 --> 0.683941).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 202\n",
      "Epoch: 2/20... Train Loss: 0.688147... Val Loss: 0.586736\n",
      "Validation loss decreased (0.683941 --> 0.586736).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 225\n",
      "Epoch: 2/20... Train Loss: 0.675581... Val Loss: 0.544489\n",
      "Validation loss decreased (0.586736 --> 0.544489).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Changing the number of intermediate evals at epoch 3\n",
      "225\n",
      "[15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 195, 210]\n",
      "Step: 15\n",
      "Epoch: 3/20... Train Loss: 0.522618... Val Loss: 0.424934\n",
      "Validation loss decreased (0.544489 --> 0.424934).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 30\n",
      "Epoch: 3/20... Train Loss: 0.501997... Val Loss: 0.538959\n",
      "Step: 45\n",
      "Epoch: 3/20... Train Loss: 0.486169... Val Loss: 0.413468\n",
      "Validation loss decreased (0.424934 --> 0.413468).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 60\n",
      "Epoch: 3/20... Train Loss: 0.463758... Val Loss: 0.376476\n",
      "Validation loss decreased (0.413468 --> 0.376476).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 75\n",
      "Epoch: 3/20... Train Loss: 0.447413... Val Loss: 0.343968\n",
      "Validation loss decreased (0.376476 --> 0.343968).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 90\n",
      "Epoch: 3/20... Train Loss: 0.435739... Val Loss: 0.353221\n",
      "Step: 105\n",
      "Epoch: 3/20... Train Loss: 0.427501... Val Loss: 0.340108\n",
      "Validation loss decreased (0.343968 --> 0.340108).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 120\n",
      "Epoch: 3/20... Train Loss: 0.418500... Val Loss: 0.344031\n",
      "Step: 135\n",
      "Epoch: 3/20... Train Loss: 0.410102... Val Loss: 0.335157\n",
      "Validation loss decreased (0.340108 --> 0.335157).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 150\n",
      "Epoch: 3/20... Train Loss: 0.403089... Val Loss: 0.338640\n",
      "Step: 165\n",
      "Epoch: 3/20... Train Loss: 0.397376... Val Loss: 0.338006\n",
      "Step: 180\n",
      "Epoch: 3/20... Train Loss: 0.395355... Val Loss: 0.330709\n",
      "Validation loss decreased (0.335157 --> 0.330709).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 195\n",
      "Epoch: 3/20... Train Loss: 0.391203... Val Loss: 0.324874\n",
      "Validation loss decreased (0.330709 --> 0.324874).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 210\n",
      "Epoch: 3/20... Train Loss: 0.388699... Val Loss: 0.321019\n",
      "Validation loss decreased (0.324874 --> 0.321019).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 225\n",
      "Epoch: 3/20... Train Loss: 0.385449... Val Loss: 0.315562\n",
      "Validation loss decreased (0.321019 --> 0.315562).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 15\n",
      "Epoch: 4/20... Train Loss: 0.306095... Val Loss: 0.306151\n",
      "Validation loss decreased (0.315562 --> 0.306151).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 30\n",
      "Epoch: 4/20... Train Loss: 0.320087... Val Loss: 0.307262\n",
      "Step: 45\n",
      "Epoch: 4/20... Train Loss: 0.318657... Val Loss: 0.306625\n",
      "Step: 60\n",
      "Epoch: 4/20... Train Loss: 0.324732... Val Loss: 0.310832\n",
      "Step: 75\n",
      "Epoch: 4/20... Train Loss: 0.332040... Val Loss: 0.304516\n",
      "Validation loss decreased (0.306151 --> 0.304516).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 90\n",
      "Epoch: 4/20... Train Loss: 0.334836... Val Loss: 0.304504\n",
      "Validation loss decreased (0.304516 --> 0.304504).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 105\n",
      "Epoch: 4/20... Train Loss: 0.333733... Val Loss: 0.301205\n",
      "Validation loss decreased (0.304504 --> 0.301205).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 120\n",
      "Epoch: 4/20... Train Loss: 0.331237... Val Loss: 0.292041\n",
      "Validation loss decreased (0.301205 --> 0.292041).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 135\n",
      "Epoch: 4/20... Train Loss: 0.325784... Val Loss: 0.312497\n",
      "Step: 150\n",
      "Epoch: 4/20... Train Loss: 0.323220... Val Loss: 0.309150\n",
      "Step: 165\n",
      "Epoch: 4/20... Train Loss: 0.319701... Val Loss: 0.314052\n",
      "Step: 180\n",
      "Epoch: 4/20... Train Loss: 0.318035... Val Loss: 0.296765\n",
      "Step: 195\n",
      "Epoch: 4/20... Train Loss: 0.316961... Val Loss: 0.290042\n",
      "Validation loss decreased (0.292041 --> 0.290042).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 210\n",
      "Epoch: 4/20... Train Loss: 0.315552... Val Loss: 0.305908\n",
      "Step: 225\n",
      "Epoch: 4/20... Train Loss: 0.314338... Val Loss: 0.303163\n",
      "Step: 15\n",
      "Epoch: 5/20... Train Loss: 0.271172... Val Loss: 0.291268\n",
      "Step: 30\n",
      "Epoch: 5/20... Train Loss: 0.289830... Val Loss: 0.296485\n",
      "Step: 45\n",
      "Epoch: 5/20... Train Loss: 0.283106... Val Loss: 0.311026\n",
      "Step: 60\n",
      "Epoch: 5/20... Train Loss: 0.280478... Val Loss: 0.285677\n",
      "Validation loss decreased (0.290042 --> 0.285677).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 75\n",
      "Epoch: 5/20... Train Loss: 0.276043... Val Loss: 0.293479\n",
      "Step: 90\n",
      "Epoch: 5/20... Train Loss: 0.278413... Val Loss: 0.282048\n",
      "Validation loss decreased (0.285677 --> 0.282048).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 105\n",
      "Epoch: 5/20... Train Loss: 0.279641... Val Loss: 0.334518\n",
      "Step: 120\n",
      "Epoch: 5/20... Train Loss: 0.281496... Val Loss: 0.298944\n",
      "Step: 135\n",
      "Epoch: 5/20... Train Loss: 0.284741... Val Loss: 0.291030\n",
      "Step: 150\n",
      "Epoch: 5/20... Train Loss: 0.284301... Val Loss: 0.292867\n",
      "Step: 165\n",
      "Epoch: 5/20... Train Loss: 0.281162... Val Loss: 0.319694\n",
      "Step: 180\n",
      "Epoch: 5/20... Train Loss: 0.280774... Val Loss: 0.293883\n",
      "Step: 195\n",
      "Epoch: 5/20... Train Loss: 0.281228... Val Loss: 0.278585\n",
      "Validation loss decreased (0.282048 --> 0.278585).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 210\n",
      "Epoch: 5/20... Train Loss: 0.279676... Val Loss: 0.279586\n",
      "Step: 225\n",
      "Epoch: 5/20... Train Loss: 0.279788... Val Loss: 0.273969\n",
      "Validation loss decreased (0.278585 --> 0.273969).  Saving model ...\n",
      "Using my_GloVe_CNN_0115.pt to save\n",
      "Step: 15\n",
      "Epoch: 6/20... Train Loss: 0.258873... Val Loss: 0.274294\n",
      "Step: 30\n",
      "Epoch: 6/20... Train Loss: 0.243909... Val Loss: 0.310337\n",
      "Step: 45\n",
      "Epoch: 6/20... Train Loss: 0.251103... Val Loss: 0.279655\n",
      "Step: 60\n",
      "Epoch: 6/20... Train Loss: 0.249021... Val Loss: 0.324315\n",
      "Step: 75\n",
      "Epoch: 6/20... Train Loss: 0.245298... Val Loss: 0.305531\n",
      "Step: 90\n",
      "Epoch: 6/20... Train Loss: 0.242698... Val Loss: 0.286241\n",
      "Step: 105\n",
      "Epoch: 6/20... Train Loss: 0.243408... Val Loss: 0.334483\n",
      "Step: 120\n",
      "Epoch: 6/20... Train Loss: 0.242702... Val Loss: 0.301328\n",
      "Step: 135\n",
      "Epoch: 6/20... Train Loss: 0.240129... Val Loss: 0.307505\n",
      "Step: 150\n",
      "Epoch: 6/20... Train Loss: 0.242666... Val Loss: 0.294050\n",
      "Step: 165\n",
      "Epoch: 6/20... Train Loss: 0.243030... Val Loss: 0.292713\n",
      "Step: 180\n",
      "Epoch: 6/20... Train Loss: 0.240794... Val Loss: 0.294921\n",
      "Step: 195\n",
      "Epoch: 6/20... Train Loss: 0.241113... Val Loss: 0.280956\n",
      "Step: 210\n",
      "Epoch: 6/20... Train Loss: 0.240750... Val Loss: 0.294398\n",
      "Step: 225\n",
      "Epoch: 6/20... Train Loss: 0.240329... Val Loss: 0.286294\n",
      "Step: 15\n",
      "Epoch: 7/20... Train Loss: 0.191540... Val Loss: 0.306434\n",
      "Step: 30\n",
      "Epoch: 7/20... Train Loss: 0.190288... Val Loss: 0.321724\n",
      "Step: 45\n",
      "Epoch: 7/20... Train Loss: 0.194588... Val Loss: 0.472314\n",
      "Step: 60\n",
      "Epoch: 7/20... Train Loss: 0.200250... Val Loss: 0.324527\n",
      "Step: 75\n",
      "Epoch: 7/20... Train Loss: 0.198668... Val Loss: 0.301824\n",
      "Step: 90\n",
      "Epoch: 7/20... Train Loss: 0.196011... Val Loss: 0.293731\n",
      "Step: 105\n",
      "Epoch: 7/20... Train Loss: 0.196266... Val Loss: 0.325355\n",
      "Stopping optimization... DONE!\n",
      "...DONE\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 20 \n",
    "patience = 21\n",
    "missteps = 0\n",
    "init_epoch = 1\n",
    "\n",
    "train_loader = train_loader_100\n",
    "\n",
    "eval_schedule = [1,2,3]\n",
    "inter_evals_list = [1,9,14]\n",
    "inter_evals = 9\n",
    "eval_list = [int(len(train_loader)/(inter_evals+1)*ii) for ii in range(1,inter_evals+1)]\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "\n",
    "\n",
    "# train for some number of epochs\n",
    "for e in range(init_epoch, init_epoch+epochs):\n",
    "    if missteps > patience:\n",
    "        print('...DONE')\n",
    "        break\n",
    "    if e in eval_schedule:\n",
    "        print('Changing the number of intermediate evals at epoch',e)\n",
    "        idx = eval_schedule.index(e)\n",
    "        #train_loader = loader_list[idx]\n",
    "        inter_evals = inter_evals_list[idx]\n",
    "        print(len(train_loader))\n",
    "        eval_list = [int(len(train_loader)/(inter_evals+1)*ii) for ii in range(1,inter_evals+1)]\n",
    "        print(eval_list)\n",
    "        \n",
    "    net.train()\n",
    "    # batch loop\n",
    "    train_loss = 0.0\n",
    "    train_size = 0\n",
    "    step = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        net.train()\n",
    "        step+=1\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #Number of items in the batch\n",
    "        train_size += inputs.size(0)\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "        # get the output from the model\n",
    "        output = net(inputs)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        if step in eval_list + [len(train_loader)]:\n",
    "            print('Step:', step)\n",
    "            \n",
    "            # Get validation loss\n",
    "            valid_loss = 0.0\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                #Compute validation loss\n",
    "                output = net(inputs)\n",
    "                valid_loss += criterion(output.squeeze(), labels.float()).item()\n",
    "\n",
    "            # Print results\n",
    "            print(\"Epoch: {}/{}...\".format(e, epochs),\n",
    "                  \"Train Loss: {:.6f}...\".format(train_loss/train_size),\n",
    "                  \"Val Loss: {:.6f}\".format(valid_loss/len(valid_loader.dataset)))\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                missteps = 0  \n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min/len(valid_loader.dataset),\n",
    "                valid_loss/len(valid_loader.dataset)))\n",
    "                save_checkpoint(my_path, net, optimizer, epoch=e, train_loss=train_loss, valid_loss=valid_loss,\n",
    "                                words=net.words, word_to_int= net.word_to_int, params=net.get_params())\n",
    "                valid_loss_min = valid_loss\n",
    "            else:\n",
    "                missteps+=1\n",
    "                if missteps > patience:\n",
    "                    print('Stopping optimization... DONE!')\n",
    "                    break\n",
    "        \n",
    "else:\n",
    "    print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentCNN(\n",
       "  (embedding): Embedding(400002, 300, padding_idx=0)\n",
       "  (conv_1a): Conv2d(1, 8, kernel_size=(1, 300), stride=(1, 1))\n",
       "  (conv_1b): Conv2d(1, 16, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_1c): Conv2d(1, 32, kernel_size=(5, 300), stride=(1, 1), padding=(2, 0))\n",
       "  (conv_2a): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_2b): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_2c): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (maxpool_3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv_3): Conv2d(56, 112, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_4): Conv2d(112, 112, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_5): Conv2d(112, 224, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_6): Conv2d(224, 224, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (conv_7): Conv2d(224, 224, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "  (fc1): Linear(in_features=224, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout2d): Dropout2d(p=0)\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (relu): ReLU()\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch, train_loss, valid_loss = load_checkpoint(my_path, net, optimizer)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing\n",
    "\n",
    "We will test or neural network in two ways\n",
    "\n",
    "* **Test data performance:** First, we'll see how our trained model performs on all of our defined test_data, above. We'll calculate the average loss and accuracy over the test data, and plot some parameters to assess the model.\n",
    "\n",
    "* **Inference on user-generated data:** Second, we'll see if we can input just one example review at a time (without a label), and see what the trained model predicts and if the results are the ones expected based on the sentiment we infer from the used sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2846\n",
      "Test accuracy: 0.8797\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_loss = 0.0 # track loss\n",
    "num_correct = 0\n",
    "test_probas = []\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = net(inputs)\n",
    "    test_probas.extend(output.squeeze().detach().cpu().numpy())\n",
    "    # calculate loss\n",
    "    test_loss += criterion(output.squeeze(), labels.float()).item()\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    #correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# Convert test_probas to numpy array\n",
    "test_probas = np.array(test_probas)\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.4f}\".format(test_loss/len(test_loader.dataset)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the predictions annd the test lables\n",
    "with open('GloVe_CNN_probas.pkl','wb') as f:\n",
    "    pickle.dump(test_probas, f)\n",
    "with open('test_y.pkl','wb') as f:\n",
    "    pickle.dump(test_y, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_1</th>\n",
       "      <th>Pred_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Label_1</th>\n",
       "      <td>11284</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_0</th>\n",
       "      <td>1792</td>\n",
       "      <td>10708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred_1  Pred_0\n",
       "Label_1   11284    1216\n",
       "Label_0    1792   10708"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cm = pd.DataFrame(cm(test_y, test_probas>=0.5, labels=[1,0]), index=['Label_1', 'Label_0'], columns=['Pred_1','Pred_0'] )\n",
    "test_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the errors are due to negative reviews misclassified as positive reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's provide some metrics for the classification focused on the possitive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8797\n",
      "Precision of the model for positive reviews: 0.8630\n",
      "Recall of the model for positive reviews: 0.9027\n",
      "f1-score of the model for positive reviews: 0.8824\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the model: {accuracy_score(test_y, test_probas>=0.5):.4f}')\n",
    "print(f'Precision of the model for positive reviews: {precision_score(test_y, test_probas>=0.5, pos_label=1):.4f}')\n",
    "print(f'Recall of the model for positive reviews: {recall_score(test_y, test_probas>=0.5, pos_label=1):.4f}')\n",
    "print(f'f1-score of the model for positive reviews: {f1_score(test_y, test_probas>=0.5, pos_label=1):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's provide some metrics for the classification focused on the negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8797\n",
      "Precision of the model for negative reviews: 0.8980\n",
      "Recall of the model for negative reviews: 0.8566\n",
      "f1-score of the model for negative reviews: 0.8768\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of the model: {accuracy_score(test_y, test_probas>=0.5):.4f}')\n",
    "print(f'Precision of the model for negative reviews: {precision_score(test_y, test_probas>=0.5, pos_label=0):.4f}')\n",
    "print(f'Recall of the model for negative reviews: {recall_score(test_y, test_probas>=0.5, pos_label=0):.4f}')\n",
    "print(f'f1-score of the model for negative reviews: {f1_score(test_y, test_probas>=0.5, pos_label=0):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the precision-recall curves for positive and negative reviews look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive reviews\n",
    "pos_pre_rec = pd.DataFrame({name: values for values, name in \n",
    "                            zip(precision_recall_curve(test_y, test_probas, pos_label=1)[:2],['precision','recall'])})\n",
    "#Negative reviews\n",
    "neg_pre_rec = pd.DataFrame({name: values for values, name in \n",
    "                            zip(precision_recall_curve(test_y, 1-test_probas, pos_label=0)[:2],['precision','recall'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=1,figsize=(10,5))\n",
    "#Positive reviews\n",
    "ax = plt.subplot(1,2,1) \n",
    "sns.lineplot(x='recall',y='precision',data=pos_pre_rec,ax=ax,color='green', alpha=0.5)\n",
    "plt.fill_between(pos_pre_rec.recall.values, pos_pre_rec.precision.values, color='green', alpha=0.3)\n",
    "plt.title('Positive Class')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "#Negative reviews\n",
    "ax = plt.subplot(1,2,2) \n",
    "sns.lineplot(x='recall',y='precision',data=neg_pre_rec,ax=ax,color='red', alpha=0.5)\n",
    "plt.fill_between(neg_pre_rec.recall.values, neg_pre_rec.precision.values, color='red', alpha=0.3)\n",
    "plt.title('Negative Class')\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check how the average probability of being positive and the percentage of predicted positive reviews varies \n",
    "with the number of stars of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Avg Prob</th>\n",
       "      <th>Pos Revs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.119457</td>\n",
       "      <td>7.526882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.162954</td>\n",
       "      <td>10.947003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.229934</td>\n",
       "      <td>17.906336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.310786</td>\n",
       "      <td>26.831120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.756975</td>\n",
       "      <td>82.964889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.829282</td>\n",
       "      <td>89.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.862247</td>\n",
       "      <td>92.363481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.872964</td>\n",
       "      <td>93.198640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars  Avg Prob   Pos Revs\n",
       "0      1  0.119457   7.526882\n",
       "1      2  0.162954  10.947003\n",
       "2      3  0.229934  17.906336\n",
       "3      4  0.310786  26.831120\n",
       "4      7  0.756975  82.964889\n",
       "5      8  0.829282  89.333333\n",
       "6      9  0.862247  92.363481\n",
       "7     10  0.872964  93.198640"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = np.unique(test_stars)\n",
    "stars.sort()\n",
    "my_df={'Stars': stars, \n",
    "       'Avg Prob':[test_probas[test_stars==i].mean() for i in stars],\n",
    "      'Pos Revs': [(test_probas[test_stars==i]>=0.5).mean()*100 for i in stars]}\n",
    "\n",
    "my_df = pd.DataFrame(my_df)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=2,figsize=(5,5))\n",
    "sns.barplot(x='Stars',y='Avg Prob',data=my_df)\n",
    "plt.title('Average Probability of Being Positive')\n",
    "plt.ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the higher the stars awarded to the review the higher the probability of it being positive based on our model (at least on average) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=3,figsize=(5,5))\n",
    "sns.barplot(x='Stars',y='Pos Revs',data=my_df)\n",
    "plt.title('Percentage of Predicted Positive Reviews')\n",
    "plt.ylim(0,100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the higher the stars awarded to a given review, the easier for the model to identify it as positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on a test review\n",
    "\n",
    "Let's write a predict function which will output if a provided review is positive or negative, as well as the probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, test_review, sequence_length=None, alignment='right'):\n",
    "    ''' Prints out whether a give review is predicted to be \n",
    "        positive or negative in sentiment, using a trained model.\n",
    "        \n",
    "        params:\n",
    "        net - A trained net \n",
    "        test_review - a review made of normal text and punctuation\n",
    "        sequence_length - the padded length of a review\n",
    "        '''\n",
    "    #Default sequence aligment: the one provided by the model if any\n",
    "    if sequence_length is None:\n",
    "        sequence_length = net.seq_length\n",
    "    #get lower case review\n",
    "    test_review = test_review.lower()\n",
    "    #remove some contractions\n",
    "    test_review = remove_contractions(test_review)\n",
    "    #remove punctuation\n",
    "    test_review = ''.join([c for c in test_review if c not in punctuation])\n",
    "    #split in words\n",
    "    test_review = test_review.split()\n",
    "    #Encode the words\n",
    "    unk = net.word_to_int.get('<unk>')\n",
    "    test_review = [[net.word_to_int.get(word,unk) for word in test_review[:sequence_length]]]\n",
    "    #Padding\n",
    "    test_review = pad_features(test_review, sequence_length, alignment=alignment)\n",
    "    #Convert into pytorch tensor\n",
    "    test_review = torch.from_numpy(test_review).type(torch.LongTensor).to(device)\n",
    "    \n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    pred = net(test_review).squeeze().item()\n",
    "    if pred >= 0.5:\n",
    "        pred = ('Positive', pred)\n",
    "    else:\n",
    "        pred = ('Negative', pred)\n",
    "    return pred\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative test review\n",
    "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive test review\n",
    "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Negative', 0.0018982893088832498)\n",
      "('Positive', 0.8960710167884827)\n"
     ]
    }
   ],
   "source": [
    "# call function for positive and negative reviews\n",
    "print(predict(net, test_review_neg, alignment='center'))\n",
    "print(predict(net, test_review_pos, alignment='center'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dependency of the Predictions on the Length of the Sequence\n",
    "\n",
    "We have implemented our CNN in such a way that we only send to the classifier (fully connected network) a fixed number of values per filter. Then we can actually use sequences of diffetrent lengths without modifying the net. Out of curiosity, we will test how the size of the sequences modifies the predictions for the longest misclassified review and for the longest review correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the corretly classified review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the review: 2328\n",
      "Stars: 10\tLabel: 1\tPrediction:0.9935\n"
     ]
    }
   ],
   "source": [
    "test_goodies_mask = ((test_y) == (test_probas>0.5))\n",
    "test_goodies_idx = np.arange(0,len(test_y),dtype=np.int)[test_goodies_mask]\n",
    "test_goodies_lens = np.array([len(test_reviews_int[idx]) for idx in test_goodies_idx])\n",
    "argmax = test_goodies_lens.argmax()\n",
    "my_idx = test_goodies_idx[argmax]\n",
    "print(f\"Length of the review: {len(test_reviews_int[my_idx])}\")\n",
    "print(f\"Stars: {test_stars[my_idx]}\\tLabel: {test_y[my_idx]}\\tPrediction:{test_probas[my_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review:\n",
      "There's a sign on The Lost Highway that says:<br /><br />*MAJOR SPOILERS AHEAD*<br /><br />(but you already knew that, didn't you?)<br /><br />Since there's a great deal of people that apparently did not get the point of this movie, I'd like to contribute my interpretation of why the plot makes perfect sense. As others have pointed out, one single viewing of this movie is not sufficient. If you have the DVD of MD, you can \"cheat\" by looking at David Lynch's \"Top 10 Hints to Unlocking MD\" (but only upon second or third viewing, please.) ;)<br /><br />First of all, Mulholland Drive is downright brilliant. A masterpiece. This is the kind of movie that refuse to leave your head. Not often are the comments on the DVDs very accurate, but Vogue's \"It gets inside your head and stays there\" really hit the mark.<br /><br />David Lynch deserves praise for creating a movie that not only has a beautifully stylish look to it - cinematography-wise, has great acting (esp. Naomi Watts), a haunting soundtrack by Badalamenti, and a very dream-like quality to it -- but on top of it all it also manages to involve the viewer in such a way that few movies have before. (After all, when is the last time you saw a movie that just wouldn't leave your mind and that everyone felt compelled to talk and write about, regardless of whether they liked it or hated it?)<br /><br />Allright, enough about all that, it's time to justify those statements.<br /><br />Most people that have gone through some effort to try to piece the plot together will have come to the conclusion that the first half of the picture is an illusion/a dream sequence.<br /><br />Of course, that's too bad for all those trying to make sense of the movie by expecting \"traditional\" methods in which the story is laid out in a timely, logic and linear manner for the viewer. But for those expecting that, I urge you to check the name of the director and come back again. ;)<br /><br />MD is the story of the sad demise of Diane Selwyn, a wannabe-actor who is hopelessly in love with another actor, Camilla Rowles. Due to Diane's lack of talent, she is constantly struggling to advance her career, and feels she failed to deliver on her own and her parents' expectations. Upon realizing that Camilla will never be hers (C. becomes engaged with Adam Kesher, the director), she hires a hitman to get rid of her, and subsequently has to deal with the guilt that it produces.<br /><br />The movie first starts off with what may seem as a strange opening for this kind of thriller; which is some 50s dance/jitterbug contest, in which we can see the main character Betty giving a great performance. We also see an elderly couple (which we will see twice more throughout the movie) together with her, and applauding her.<br /><br />No, wait. This is what most people see the first time they view it. There's actually another very significant fact that is given before the credits - the camera moving into an object (although blurry) and the scene quickly fading out. If you look closely, the object is actually a pillow, revealing that what follows is a dream.<br /><br />The main characters seen in the first half of the movie:<br /><br />Betty: Diane Selwyn's imaginary self, used in the first half of the movie that constitutes the \"dream-sequence\" - a positive portrayal of a successful, aspiring young actor (the complete opposite of Diane). 'Betty' was chosen as the name as that is the real name of the waitress at Winkies. Notice that in the dream version, the waitresses' name is 'Diane'.<br /><br />Rita: The fantasy version of Camilla Rhodes that, through Diane's dream, and with the help of an imaginary car-accident, is turned into an amnesiac. This makes her vulnerable and dependent on Diane's love. She is then conveniently placed in Betty/Diane's aunt's luxurious home which Betty has been allowed to stay in.<br /><br />Coco: In real life, Adam's mother. In the dream part, the woman in charge of the apartment complex that Betty stays in. She's mainly a strong authority figure, as can be witnessed in both parts of the film.<br /><br />Adam: The director. We know from the second half that he gets engaged with Camilla. His sole purpose for being in the first half of the movie is only to serve as a punching bag for Betty/Diane, since she develops such hatred towards him.<br /><br />Aunt Ruth: Diane's real aunt, but instead of being out of town, she is actually dead. Diane inherited the money left by her aunt and used that to pay for Camilla's murder.<br /><br />Mr. Roach: A typical Lynchian character. Not real; appears only in Diane's dream sequence. He's a mysterious, influential person that controls the chain of events in the dream from his wheelchair. He serves much of the same function as the backwards-talking dwarf (which he also plays) in Twin Peaks.<br /><br />The hitman: The person that murders Camilla. This character is basically the same in both parts of the movie, although rendered in a slightly more goofy fashion in the dream sequence (more on that below).<br /><br />Now, having established the various versions of the characters in the movie, we can begin to delve into the plot. Of course I will not go into every little detail (neither will I lay it out chronologically), but I will try to explain some of the important scenes, in relation to Lynch' \"hint-sheet\".<br /><br />As I mentioned above, Camilla was re-produced as an amnesiac through her improbable survival of a car-accident in the first 10 minutes of the movie, which left her completely vulnerable. What I found very intriguing with MD, is that Lynch constantly gives hints on what is real and what isn't. I've already mentioned the camera moving into the pillow, but notice how there's two cars riding in each lane approaching the limo.<br /><br />Only one of the cars actually hit the limo; what about the other? Even if they stayed clear of the accident themselves, wouldn't they try to help the others, or at least call for help? My theory is that, since this is a dream, the presence of the other car is just set aside, and forgotten about. Since, as Rogert Ebert so eloquently puts it \"Like real dreams, it does not explain, does not complete its sequences, lingers over what it finds fascinating, dismisses unpromising plotlines.\"<br /><br />Shortly after Rita crawls down from the crash site at Mulholland Dr., and makes her way down the hillside and sneaks into Aunt Ruth's apartment, Betty arrives and we see this creepy old couple driving away, staring ghoulishly at each other and grinning at themselves and the camera. This is the first indication that what we're seeing is a nightmare.<br /><br />Although the old couple seem to be unfamiliar to Betty, I think they're actually her parents (since they were applauding her at the jitterbug contest). Perhaps she didn't know them all that well, and didn't really have as good a relationship with them as she wanted, so the couple is shown as very pleasant and helpful to her in the dream. They also represent her feelings of guilt from the murder, and Diane's sense of unfulfillment regarding her unachieved goals in her life.<br /><br />A rather long and hilarious scene is the one involving the hitman. Diane apparently sees him as the major force behind the campaign trying to pressure the director to accept Camilla's part in the movie (from Adam's party in the second half of the movie), and he therefore occupies a major part of her dream. Because of her feelings of guilt and remorse towards the murder of Camilla, a part of her wants him to miss, so she turns him into a dumb criminal.<br /><br />This scene, I think, is also Lynch's attempt at totally screwing his audience over, since they're given a false pretence in which to view the movie.<br /><br />Gotta love that 'Something just bit me bad' line, though. :)<br /><br />The next interesting scene is the one with the two persons at Twinkies, who are having a conversation about how one of them keep having this recurring nightmare involving a man which is seen by him through a wall outside of the diner that they're sitting in. After a little talk, they head outside and keep walking toward the corner of a fence, accompanied of course by excellent music matching the mood of the scene.<br /><br />When reaching the corner, a bum-like character with a disfigured face appears out from behind the corner, scaring the living crap out of the man having the nightmare. This nightmare exists only in Diane's mind; she saw that guy in the diner when paying for the murder. So, in short, her obessions translate into that poor guy's nightmares. The bum also signifies Diane's evil side, as can be witnessed later in the movie.<br /><br />The Cowboy constitutes (along with the dwarf) one of the strange characters that are always present in the Lynchian landscape -- Diane only saw him for a short while at Adam's party, but just like our own dreams can award insignificant persons that we hardly know a major part in our dreams, so can he be awarded an important part in her dream. We are also given further clues during his scenes that what we're seeing is not real (his sudden disappearance, etc.)<br /><br />The Cowboy is also used as a tool to mock the Director, when he meets up with him at the odd location (the lights here give a clear indication that this is part of a dream). Also notice how he says that he will appear one more time if he (Adam) does good, or two more times if he does bad. Throughout the movie he appears two more times, indicating to Diane that she did bad. He is also the one to wake her up to reality (that scene is probably an illusion made to fit into her requirements of him appearing twice), and shortly thereafter she commits suicide.<br /><br />The espresso-scene with the Castigliane brothers (where we can see Badalamenti, the composer, as Luigi) is probably a result of the fact that Diane was having an espresso just before Camilla and Adam made their announcement at Adam's party in the second half. It could at the same time also be a statement from Lynch.<br /><br />During the scene in which they enter Diane's apartment, the body lying in the bed is Camilla, but notice how she's assumed Diane's sleeping position; Diane is seeing herself in her own dream, but the face is not hers, although it had the same wounds on the face as Diane would have after shooting herself. This scene is also filled with some genuine Lynchian creepiness. Since Diane did not know where (or when) the hitman would get to Camilla and finish her off, she just put her into her own home.<br /><br />In real life, Diane's audition for the movie part was bad. In her dream, she delivers a perfect audition - leaving the whole crew ecstatic about her performance.<br /><br />Also interesting is the fact that the money that in real-life was used to pay for Camilla's murder now appears in Rita/Camilla's purse. This is part of Diane's undoing of her terrible act by effectively being given the money back, as the murder now hasn't taken place.<br /><br />When her neighbor arrives to get her piano-shaped ashtray, another hint is given; she takes the ashtray from her table and leaves, yet later when Camilla and Betty have their encounter on the couch, we see the ashtray appear again when the camera pans over the table, suggesting that Betty's encounter with the neighbor was a fantasy.<br /><br />The catch phrase of the movie Adam is auditioning actresses for is \"She is the girl\"; which are the exact same words that Diane uses when giving the hitman Camilla's photo resume.<br /><br />The blue box and the key represent the major turning point in the movie, and is where the true identities of the characters are revealed. There's much symbolism going on here; the box may represent Diane's future (it's empty), or it may be a sort of a Pandora's box (the hitman laughs when she asks him what the key will open). Either way, it is connected to the murder by means of the blue key (which is placed next to her after the murder has taken place). The box is also seen at the end of the movie in the hands of the disfigured bum.<br /><br />Club Silencio is a neat little addition to further remind the viewer that what s/he is viewing is not real. It also signifies that Diane is about to wake up to her reality (her reality being a nightmare that she is unable to escape from, even in her dreams).<br /><br />During the chilling scene at the end where the creepy old couple reappear, Diane is tormented in such a way that she sees suicide as the only way out in order to escape the screams and to avoid being haunted by her fears.<br /><br />Anyway, that is my $0.02. Hope this could help people from bashing out at this movie and calling it 'the worst movie ever' or something to that effect, without realizing the plot.<br /><br />As usual, Lynch is all about creating irrational fears, and he certainly achieves that with this picture as well.<br /><br />10 out of 10.\n"
     ]
    }
   ],
   "source": [
    "print('The review:')\n",
    "with open(test_pos_dir+test_pos_rev_files[my_idx], 'r',encoding=\"utf8\") as f:\n",
    "    my_review=f.read()\n",
    "    print(my_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:200\t('Positive', 0.9959287047386169)\n",
      "Length:250\t('Positive', 0.9959102869033813)\n",
      "Length:300\t('Positive', 0.9936336278915405)\n",
      "Length:350\t('Positive', 0.9934701919555664)\n",
      "Length:400\t('Positive', 0.9908819198608398)\n",
      "Length:450\t('Positive', 0.9893413186073303)\n",
      "Length:500\t('Positive', 0.9890527129173279)\n",
      "Length:550\t('Positive', 0.9890523552894592)\n",
      "Length:600\t('Positive', 0.9890523552894592)\n",
      "Length:650\t('Positive', 0.9890790581703186)\n",
      "Length:700\t('Positive', 0.9890790581703186)\n",
      "Length:750\t('Positive', 0.9890790581703186)\n",
      "Length:800\t('Positive', 0.9889841675758362)\n",
      "Length:850\t('Positive', 0.9888788461685181)\n",
      "Length:900\t('Positive', 0.9888788461685181)\n",
      "Length:950\t('Positive', 0.9888788461685181)\n",
      "Length:1000\t('Positive', 0.9889276027679443)\n",
      "Length:1050\t('Positive', 0.9889060258865356)\n",
      "Length:1100\t('Positive', 0.9888917803764343)\n",
      "Length:1150\t('Positive', 0.9888917803764343)\n",
      "Length:1200\t('Positive', 0.9888917803764343)\n",
      "Length:1250\t('Positive', 0.9888893365859985)\n",
      "Length:1300\t('Positive', 0.9888896942138672)\n",
      "Length:1350\t('Positive', 0.988889217376709)\n",
      "Length:1400\t('Positive', 0.9826299548149109)\n",
      "Length:1450\t('Positive', 0.9781826734542847)\n",
      "Length:1500\t('Positive', 0.9781826734542847)\n",
      "Length:1550\t('Positive', 0.9781807065010071)\n",
      "Length:1600\t('Positive', 0.9781826734542847)\n",
      "Length:1650\t('Positive', 0.9781826734542847)\n",
      "Length:1700\t('Positive', 0.9781826734542847)\n",
      "Length:1750\t('Positive', 0.9781555533409119)\n",
      "Length:1800\t('Positive', 0.978152334690094)\n",
      "Length:1850\t('Positive', 0.9778362512588501)\n",
      "Length:1900\t('Positive', 0.9778361320495605)\n",
      "Length:1950\t('Positive', 0.9778361320495605)\n",
      "Length:2000\t('Positive', 0.9734799265861511)\n",
      "Length:2050\t('Positive', 0.9734625220298767)\n",
      "Length:2100\t('Positive', 0.9687530398368835)\n",
      "Length:2150\t('Positive', 0.9687530398368835)\n",
      "Length:2200\t('Positive', 0.9687530398368835)\n",
      "Length:2250\t('Positive', 0.9687530398368835)\n",
      "Length:2300\t('Positive', 0.9593256115913391)\n"
     ]
    }
   ],
   "source": [
    "for sl in range(200,len(test_reviews_int[my_idx]),50):\n",
    "    print(f\"Length:{sl}\\t{predict(net, my_review, sequence_length=sl, alignment='center')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independently of the size, the network predicts a possitive sentiment (the correct result). The probabilities barely change (0.96-1.00)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it affects the misclassified review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the review: 2147\n",
      "Stars: 7\tLabel: 1\tPrediction:0.0035\n"
     ]
    }
   ],
   "source": [
    "test_error_mask = ((test_y) == (test_probas<0.5))\n",
    "test_erorr_idx = np.arange(0,len(test_y),dtype=np.int)[test_error_mask]\n",
    "test_error_lens = np.array([len(test_reviews_int[idx]) for idx in test_erorr_idx])\n",
    "argmax = test_error_lens.argmax()\n",
    "my_idx = test_erorr_idx[argmax]\n",
    "print(f\"Length of the review: {len(test_reviews_int[my_idx])}\")\n",
    "print(f\"Stars: {test_stars[my_idx]}\\tLabel: {test_y[my_idx]}\\tPrediction:{test_probas[my_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review:\n",
      "(Some spoilers included:)<br /><br />Although, many commentators have called this film surreal, the term fits poorly here. To quote from Encyclopedia Britannica's, surreal means:<br /><br />\"Fantastic or incongruous imagery\": One needn't explain to the unimaginative how many ways a plucky ten-year-old boy at large and seeking his fortune in the driver's seat of a red Mustang could be fantastic: those curious might read James Kincaid; but if you asked said lad how he were incongruous behind the wheel of a sports car, he'd surely protest, \"NO way!\" What fantasies and incongruities the film offers mostly appear within the first fifteen minutes. Thereafter we get more iterations of the same, in an ever-cruder and more squalid progression that, far from incongruous, soon proves predictable. Not that it were, on the other hand, literally believable-- but it were unfair to tax Motorama in particular with this flaw, any plausible suspension of disbelief having fallen precipitously on the typical film-maker's and viewer's scale of values ever since \"Raiders of the Lost Ark\" became a blockbuster.<br /><br />\"Hallucinatory\": How do we know what a hallucination is if part of having one is not knowing that we are having one? At any rate, some people know that they enjoy \"hallucinogenic drugs\"-- but if Motorama typifies the result of doing so, then I'm at a loss as to why anyone would take them more than once. There is, of course, the occasional bad trip. The movie must be one of those, pun and all.<br /><br />\"Juxtaposition of words that was startling\": How many times can a ten-year-old startle you by uttering \"Oh, my God!\" when he likes something, or \"Damn!\" when he doesn't? These two interjections are about par for the course with this script. Sadly, any sense of the surreal in what passes for dialogue could only reveal, in direct proportion, one's naivete regarding the speech patterns of the rising American generation.<br /><br />\"A world completely defined and minutely depicted but that makes no rational sense:\" Motorama's world indeed makes no sense, but it is about as completely defined as a cartoon in an elementary school newspaper. The numerous guest stars in the cast all have cameo roles even less intelligent than our little hero who exclaims \"Damn!\" in the blink of an eyelash but needs several seconds to concoct the lamest lie. And even *his* character, despite appearing in nearly every scene, gets no significant development. Here's scant reward for any viewer who sympathizes, as I must, enough to wish to know him better and understand 'where he's coming from.' One vaguely senses a far better story and protagonist struggling to get out.<br /><br />\"Fully recognizable, realistically painted images are removed from their normal contexts and reassembled within an ambiguous, paradoxical, or shocking framework.\" No, we see a succession of stereotypical and ever more dilapidated billboards, filling stations, greasy-spoon eateries, cheap hotels, and their lowlife habitues along country highways, exactly where they stereotypically belong.<br /><br />\"Largely responsible for perpetuating... the traditional emphasis on content.\" There is little content, moment-to-moment, in Motorama.<br /><br />To sum up: Picture British millionaires dressed as clowns or pirates on the way to a posh costume party, sitting serene and mute as cautious chauffeurs inch their Rolls-Royces like fragile skiffs through a roiling sea of desperate humanity, Chinese who implore them through the windows and smear the glass with blood. Or imagine a stadium full of abandoned antiques, limousines like those above now rusting, and white pianos tinkled by ghosts. Into this detritus wander an exhausted boy and an ailing woman to whom he clings as mother-figure becoming girl-friend, who fall asleep side by side on the grass. He is awakened-- on the Feast of the Transfiguration, \"white and glistering\" day 1945-- by a brilliant flash on the horizon that is not the rising sun. Finding that his consort has become a corpse, he first believes that he has witnessed her soul going up to heaven. Later he explains only a little less innocently, 'I learned a new word today: atom-bomb. It's like God taking a photograph.' Now, *there* are just two samples of cinematic surrealism, surrealism whose ironies ripple out far enough to invade its film's very title: Empire of the Sun. If you seek surreal, *please* don't miss it. Alas, however hard he treads on the accelerator to race his chariot through and beyond the desert, no scenes so exquisitely strange, rich, subtle, or gorgeous await Motorama's poor little Gus in his quest.<br /><br />None of the above necessarily constitutes a thumbs-down on this film. Though somewhat disappointed, I can't dismiss it, in view of the respectability of another genre that it does exemplify-- one influenced, to be sure, by surrealism, but also by expressionism, existentialism, and Franz Kafka's pessimism amidst omnipotent power structures. Let's try on for size: Theater of the Absurd.<br /><br />Turning to E.B.'s article on this style, I am amazed by how, to the extent that Theater of the Absurd is a valid artistic style, the above objections to Motorama vanish like a puff of smoke. I'm tempted to quote the entire text as support of the identification.<br /><br />Theater of the Absurd attempts to show \"that the human situation is essentially absurd, devoid of purpose... humankind is left feeling hopeless, bewildered, and anxious.\": Having instantaneously achieved his purpose of getting away from a depressing home life among bickering parents, Gus finds himself purposeless until he drives past a glittering billboard reading \"Motorama\" and decides to win the lottery that it promises. As others have already revealed, this ambition proves illusory: although the game \"never expires\", the sponsoring corporation has no intention that anyone should ever win, and has ways to trick, confuse, and leave crestfallen any aspirant to the reward. He, like others, is ultimately disappointed in his dream.<br /><br />\"Absurdist playwrights, therefore, did away with most of the logical structure of traditional theatre. There is little dramatic action as conventionally understood; however frantically the characters perform, their busyness serves to underscore the fact that nothing happens to change their existence... a timeless, circular quality emerges.\" \"Language in an absurdist play is full of... repetitions... repeating the obvious until it sounds like nonsense.\" Underneath a sometimes \"dazzling comic surface,\" we find \"an underlying message of metaphysical distress.\" Gus's obsession with a silly game, his inane language, the plot device wherein he divines a bleak future and/or returns to an earlier moment and takes a different but still bleak turn-- so much fits now. While an admirer of the surreal would do better with some films, anyway, of Spielberg, admirers of Motorama as it really is should find fellow-travelers-- not instead but addition-- in the works of Beckett, Ionesco, and Genet.<br /><br />But one can't quite stop here. After his disillusionment with the game, Gus returns to \"Phil\" (i.e., Love), the first attendant he had met and the one person who had treated him decently, although he had also scolded him-- at a service station advertising \"Be full-filled!\". Under Phil's tutelage he learns a life of waiting for cars. We might note here that the absurdist playwright Beckett had entitled his most famous play \"Waiting for Godot,\" and that for Godot we should read \"God.\" God is one of Phil's preoccupations, too. Furthermore, as the indirect result of his previous encounter with Gus, Phil is badly maimed and goes about in a cast with his arms straight out horizontally. In the last scene, Gus, now Phil's protege, says that he wants to hear music. We hear none, but we see Phil wiggling his fingers at the end of his outstretched arm, beckoning Gus closer, and Gus responds. The End.<br /><br />Finally, on to an author whom I happen to be reading currently, the Anglican theologian William Stringfellow. If this rebel-lawyer is not acknowledged as an architect or undergirder of Liberation Theology, which is more a Roman Catholic than an Anglican movement, perhaps he should be. Police brutality and corporate greed are a cliche in cinema and literature, including Motorama, but Stringfellow supports and illuminates such sentiments with impressive warrants from scripture, tradition, and reason.<br /><br />His most significant work is an expose of the earthly activities of those fallen angels whom the Bible refers to as principalities and powers. Principalities, wrote Stringfellow, are behind all of our popular three I's: Images, Institutions, and Ideologies. All of these commend themselves to our worship by making false promises. The more deeply involved with an image, an institution, or an ideology any person becomes, the more his own personhood becomes \"depleted\" and be becomes a slave to them. Promising power, control, and immortality, they inexorably deliver helplessness, chaos, and death. As essentially fallen, defeated powers, they can do no more than that. Yet they beguile humans with that \"dominion over the earth\" promised by God in the book of Genesis, while in fact no one of us controls an image, an institution, or an ideology bent inevitably on its own hegemony and self-preservation. They take on lives of their own. \"Dominion\" happens to be a mistranslation: a more accurate rendering of the Hebrew would be \"stewardship.\" But this is a quibble beside a more fundamental problem: Most of us neglect to notice that God had delegated this power to Adam *before* the fall. We have no reason to assume that we, his descendents, still exercise it now: on the contrary, it should be obvious that demonic forces have stolen it from us.<br /><br />One might add two observations of C.S. Lewis: First, that \"man's conquest of nature\" is a mere illusion, and a ruse to cover the fact that one is really talking about the conquest of some men by other men with nature as the instrument; and secondly, contrary to popular belief, Satan is no kind of good-time Charlie. He may dangle out pleasures at first, but he is very niggardly with them and will withdraw them from any human firmly in his thrall, perhaps leaving his prey sitting in front of the fire feeling miserably sorry for himself and seething with resentment.<br /><br />Now, applying these insights to Motorama, we seem them mirrored remarkably in Gus's experience. He is, if not nice, at least a pretty little boy prior to falling victim to the Motorama game. The first signs advertising it glisten glamorously. The longer he continues, however, and the deeper he journeys towards the sponsoring corporation's headquarters, the more shabby they become. He's lonely, meeting no one else who plays the game. The stations giving out the cards have either fallen into ruins or are staffed by zombies. The people he does meet along the way are more and more ugly, deceitful, and hostile. (The fact that the principalities answer to a common dictator does not mean that they can abide one another). Gus's humanity is leached out of him as he becomes not only totally self-centered and oblivious to the needs of others but partially blinded... disfigured... prematurely aged while infantile in the literal sense of linguistically challenged. Eventually even his precious Mustang is taken from him in a crash, and he must continue in a dead man's wreck. Yet at long last, having done everything he thought was expected, he presents himself to the principality in its proud tower to receive his prize. Using the biblical power to confuse wielded by those who have built such monuments to their own vanity, its agents evade him, disappoint, insult, and finally throw him from the top floor. He FALLS long and hard, landing, finally in a body of water. In other words, in classic symbolism, he DIES. He has met the inevitable bad end of anyone who has put his faith in such a deceiver.<br /><br />But this fate proves to be only a warning look into a mutable future. He repents and returns to Phil, and upon seeing him performs the very first generous, selfless act we have seen from him for almost an hour and a half: noting that Phil is now handicapped and hardly able to insert a hose into a gas tank, he asks, \"Can I help you with that?\" Then, seeing the \"help wanted\" sign, he decides to apply for the job, explaining to the motorist with whom he was hitch-hiking that he reckons he'll get out here, because it doesn't look like too bad a place to work.<br /><br />This interpretation is conjectural, of course, and it may surprise or even outrage the film's \"cult classic\" aficionados who see quite different points in it.<br /><br />If Motorama isn't quite my cup of tea, I'm at least convinced now that it's hardly the worst film ever made.\n"
     ]
    }
   ],
   "source": [
    "print('The review:')\n",
    "with open(test_pos_dir+test_pos_rev_files[my_idx], 'r',encoding=\"utf8\") as f:\n",
    "    my_review=f.read()\n",
    "    print(my_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length:200\t('Negative', 0.1013079509139061)\n",
      "Length:250\t('Negative', 0.10831839591264725)\n",
      "Length:300\t('Negative', 0.06756401062011719)\n",
      "Length:350\t('Negative', 0.003499939339235425)\n",
      "Length:400\t('Negative', 0.004484521225094795)\n",
      "Length:450\t('Negative', 0.004481280222535133)\n",
      "Length:500\t('Negative', 0.004486116115003824)\n",
      "Length:550\t('Negative', 0.004478473216295242)\n",
      "Length:600\t('Negative', 0.004468280356377363)\n",
      "Length:650\t('Negative', 0.00792954582720995)\n",
      "Length:700\t('Negative', 0.009979079477488995)\n",
      "Length:750\t('Negative', 0.01724839396774769)\n",
      "Length:800\t('Negative', 0.01724839396774769)\n",
      "Length:850\t('Negative', 0.017377620562911034)\n",
      "Length:900\t('Negative', 0.007171474862843752)\n",
      "Length:950\t('Negative', 0.00592619925737381)\n",
      "Length:1000\t('Negative', 0.006087926682084799)\n",
      "Length:1050\t('Negative', 0.008094499818980694)\n",
      "Length:1100\t('Negative', 0.00933400820940733)\n",
      "Length:1150\t('Negative', 0.00933400820940733)\n",
      "Length:1200\t('Negative', 0.00920197181403637)\n",
      "Length:1250\t('Negative', 0.009241264313459396)\n",
      "Length:1300\t('Negative', 0.009240063838660717)\n",
      "Length:1350\t('Negative', 0.00911497138440609)\n",
      "Length:1400\t('Negative', 0.02428886853158474)\n",
      "Length:1450\t('Negative', 0.03907361254096031)\n",
      "Length:1500\t('Negative', 0.03907361254096031)\n",
      "Length:1550\t('Negative', 0.038372404873371124)\n",
      "Length:1600\t('Negative', 0.0384102463722229)\n",
      "Length:1650\t('Negative', 0.03840891644358635)\n",
      "Length:1700\t('Negative', 0.03840891644358635)\n",
      "Length:1750\t('Negative', 0.03840891644358635)\n",
      "Length:1800\t('Negative', 0.03840891644358635)\n",
      "Length:1850\t('Negative', 0.03840891644358635)\n",
      "Length:1900\t('Negative', 0.03825683146715164)\n",
      "Length:1950\t('Negative', 0.03790007531642914)\n",
      "Length:2000\t('Negative', 0.03789696469902992)\n",
      "Length:2050\t('Negative', 0.038300495594739914)\n",
      "Length:2100\t('Negative', 0.03840711712837219)\n"
     ]
    }
   ],
   "source": [
    "for sl in range(200,len(test_reviews_int[my_idx]),50):\n",
    "    print(f\"Length:{sl}\\t{predict(net, my_review, sequence_length=sl, alignment='center')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities barely depend on the sequence length (0.01-0.11). For all sequence lengths the wrong sentiment is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
